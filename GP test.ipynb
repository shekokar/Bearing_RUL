{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cross-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from scipy.linalg import cho_solve\n",
    "from pyDOE import lhs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "valid-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianProcess:\n",
    "    \"\"\"A Gaussian Process class that trains and exploits \n",
    "    a Gaussian Process model\"\"\"\n",
    "    \n",
    "    def __init__(self, n_restarts, optimizer):\n",
    "        \"\"\"Initialize a Gaussian Process model\n",
    "        \n",
    "        Input\n",
    "        ------\n",
    "        n_restarts: number of restarts of the local optimizer\n",
    "        optimizer: algorithm of local optimization\"\"\"\n",
    "        \n",
    "        self.n_restarts = n_restarts\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "       \n",
    "    def Corr(self, X1, X2, theta):\n",
    "        \"\"\"Construct the correlation matrix between X1 and X2\n",
    "        \n",
    "        Input\n",
    "        -----\n",
    "        X1, X2: 2D arrays, shape (n_samples, n_features)\n",
    "        theta: array, correlation legnths for different dimensions\n",
    "        \n",
    "        Output\n",
    "        ------\n",
    "        K: the correlation matrix\n",
    "        \"\"\"\n",
    "        K = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "        for i in range(X1.shape[0]):\n",
    "            K[i,:] = np.exp(-np.sum(theta*(X1[i,:]-X2)**2, axis=1))\n",
    "            \n",
    "        return K\n",
    " \n",
    "       \n",
    "    def Neglikelihood(self, theta):\n",
    "        \"\"\"Negative likelihood function\n",
    "        \n",
    "        Input\n",
    "        -----\n",
    "        theta: array, correlation legnths for different dimensions\n",
    "        \n",
    "        Output\n",
    "        ------\n",
    "        LnLike: likelihood value\"\"\"\n",
    "        \n",
    "        theta = 10**theta    # Correlation length\n",
    "        n = self.X.shape[0]  # Number of training instances\n",
    "        one = np.ones((n,1))      # Vector of ones\n",
    "        \n",
    "        # Construct correlation matrix\n",
    "        K = self.Corr(self.X, self.X, theta) + np.eye(n)*1e-10\n",
    "        L = np.linalg.cholesky(K)\n",
    "        #inv_K = np.linalg.inv(K)   # Inverse of correlation matrix\n",
    "        \n",
    "        # Mean estimation\n",
    "        mu = (one.T @ (cho_solve((L, True), self.y))) / \\\n",
    "            (one.T @ (cho_solve((L, True), one)))\n",
    "        # mu = (one.T @ inv_K @ self.y)/ (one.T @ inv_K @ one)\n",
    "        \n",
    "        # Variance estimation\n",
    "        SigmaSqr = (self.y-mu*one).T @ (cho_solve((L, True), self.y-mu*one)) / n\n",
    "        # SigmaSqr = (self.y-mu*one).T @ inv_K @ (self.y-mu*one) / n\n",
    "        \n",
    "        # Compute log-likelihood\n",
    "        LnDetK = 2*np.sum(np.log(np.abs(np.diag(L))))\n",
    "        # DetK = np.linalg.det(K)\n",
    "        LnLike = -(n/2)*np.log(SigmaSqr) - 0.5*LnDetK\n",
    "        \n",
    "        # Update attributes\n",
    "        self.K, self.L, self.mu, self.SigmaSqr = K, L, mu, SigmaSqr\n",
    "        \n",
    "        return -LnLike.flatten()\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"GP model training\n",
    "        \n",
    "        Input\n",
    "        -----\n",
    "        X: 2D array of shape (n_samples, n_features)\n",
    "        y: 2D array of shape (n_samples, 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X, self.y = X, y\n",
    "        lb, ub = -3, 2\n",
    "        \n",
    "        # Generate random starting points (Latin Hypercube)\n",
    "        lhd = lhs(self.X.shape[1], samples=self.n_restarts)\n",
    "        \n",
    "        # Scale random samples to the given bounds \n",
    "        initial_points = (ub-lb)*lhd + lb\n",
    "        \n",
    "        # Create A Bounds instance for optimization\n",
    "        bnds = Bounds(lb*np.ones(X.shape[1]),ub*np.ones(X.shape[1]))\n",
    "        \n",
    "        # Run local optimizer on all points\n",
    "        opt_para = np.zeros((self.n_restarts, self.X.shape[1]))\n",
    "        opt_func = np.zeros((self.n_restarts, 1))\n",
    "        for i in range(self.n_restarts):\n",
    "            res = minimize(self.Neglikelihood, initial_points[i,:], method=self.optimizer,\n",
    "                bounds=bnds)\n",
    "            opt_para[i,:] = res.x\n",
    "            opt_func[i,:] = res.fun\n",
    "        \n",
    "        # Locate the optimum results\n",
    "        self.theta = opt_para[np.argmin(opt_func)]\n",
    "        \n",
    "        # Update attributes\n",
    "        self.NegLnlike = self.Neglikelihood(self.theta)\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"GP model predicting\n",
    "        \n",
    "        Input\n",
    "        -----\n",
    "        X_test: test set, array of shape (n_samples, n_features)\n",
    "        \n",
    "        Output\n",
    "        ------\n",
    "        f: GP predictions\n",
    "        SSqr: Prediction variances\"\"\"\n",
    "        \n",
    "        n = self.X.shape[0]\n",
    "        one = np.ones((n,1))\n",
    "        \n",
    "        # Construct correlation matrix between test and train data\n",
    "        k = self.Corr(self.X, X_test, 10**self.theta)\n",
    "        \n",
    "        # Mean prediction\n",
    "        f = self.mu + k.T @ (cho_solve((self.L, True), self.y-self.mu*one))\n",
    "        # f = self.mu + k.T @ self.inv_K @ (self.y-self.mu*one)\n",
    "        \n",
    "        # Variance prediction\n",
    "        SSqr = self.SigmaSqr*(1 - np.diag(k.T @ (cho_solve((self.L, True), k))))\n",
    "        # SSqr = self.SigmaSqr*(1 - np.diag(k.T @ self.inv_K @ k))\n",
    "        \n",
    "        return f.flatten(), SSqr.flatten()\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"Calculate root mean squared error\n",
    "        \n",
    "        Input\n",
    "        -----\n",
    "        X_test: test set, array of shape (n_samples, n_features)\n",
    "        y_test: test labels, array of shape (n_samples, )\n",
    "        \n",
    "        Output\n",
    "        ------\n",
    "        RMSE: the root mean square error\"\"\"\n",
    "        \n",
    "        y_pred, SSqr = self.predict(X_test)\n",
    "        RMSE = np.sqrt(np.mean((y_pred-y_test)**2))\n",
    "        \n",
    "        return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expressed-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = pd.read_csv('./final_preprocessed_data/bearing1_1.csv',header=None)#Training data for condition 1\n",
    "X_train_2 = pd.read_csv('./final_preprocessed_data/bearing2_1.csv',header=None)#Training data for condition 2\n",
    "X_train_3 = pd.read_csv('./final_preprocessed_data/bearing3_1.csv',header=None)#Training data for condition 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geographic-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = [i/X_train_1.shape[0] for i in range(1,X_train_1.shape[0]+1)]#Target fn for condition 1\n",
    "t2 = [i/X_train_2.shape[0] for i in range(1,X_train_2.shape[0]+1)]#Target fn for condition 2\n",
    "t3 = [i/X_train_3.shape[0] for i in range(1,X_train_3.shape[0]+1)]#Target fn for condition 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "absent-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([('scaler', MinMaxScaler()), \n",
    "         ('GP', GaussianProcess(n_restarts=10, optimizer='L-BFGS-B'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "received-trainer",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many axes: 2 (effrank=2), expected rank=1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f7fa7baff3cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f79533765982>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mopt_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_restarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_restarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             res = minimize(self.Neglikelihood, initial_points[i,:], method=self.optimizer,\n\u001b[0m\u001b[1;32m    102\u001b[0m                 bounds=bnds)\n\u001b[1;32m    103\u001b[0m             \u001b[0mopt_para\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    617\u001b[0m                                   **options)\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# x, f, g, wa, iwa, task, csave, lsave, isave, dsave = \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr,\n\u001b[0m\u001b[1;32m    352\u001b[0m                        \u001b[0mpgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                        isave, dsave, maxls)\n",
      "\u001b[0;31mValueError\u001b[0m: too many axes: 2 (effrank=2), expected rank=1\n"
     ]
    }
   ],
   "source": [
    "pipe1.fit(X_train_1, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
